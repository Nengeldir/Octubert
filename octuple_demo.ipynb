{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OctupleMIDI Training Process Demo\n",
    "\n",
    "This notebook demonstrates the entire process of initializing the model and dataset for OctupleMIDI training, including a short training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.19' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3.10 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if \"PATH\" not in os.environ:\n",
    "    os.environ[\"PATH\"] = \"\"\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from hparams.set_up_hparams import HparamsOctuple\n",
    "from models.transformer import Transformer\n",
    "from utils.data_utils import OctupleDataset\n",
    "from utils.octuple import OctupleEncoding\n",
    "from models.absorbing_diffusion import AbsorbingDiffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Hyperparameters\n",
    "We initialize the HparamsOctuple class with the configuration specific to the Octuple format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockParser:\n",
    "    def __init__(self):\n",
    "        self.model = 'octuple'\n",
    "        self.n_vis = 1\n",
    "        self.visdom_port = 8097\n",
    "        self.batch_size = 4\n",
    "        self.notes = 128\n",
    "        self.bars = 8\n",
    "        self.epochs = 1\n",
    "        self.lr = 0.001\n",
    "        self.load_dir = None\n",
    "        self.log_base_dir = None\n",
    "        self.tracks = 'string'\n",
    "        self.ema = False\n",
    "        self.amp = False\n",
    "        self.load_step = 0\n",
    "        self.validation_set_size = 0.1\n",
    "\n",
    "parser = MockParser()\n",
    "H = HparamsOctuple(parser)\n",
    "print(f\"Codebook Sizes: {H.codebook_size}\")\n",
    "print(f\"Latent Shape: {H.latent_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data\n",
    "We use the `OctupleDataset` to load preprocessed `.npy` files from `data/processed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/processed\"\n",
    "# Create dummy data if it doesn't exist for demonstration purposes\n",
    "if not os.path.exists(dataset_path) or len(os.listdir(dataset_path)) == 0:\n",
    "    print(f\"Path {dataset_path} empty or missing. Creating dummy data for demonstration.\")\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "    # Create a dummy file\n",
    "    dummy_data = np.random.randint(0, 32, (200, 8)).astype(np.int64)\n",
    "    np.save(os.path.join(dataset_path, \"dummy.npy\"), dummy_data)\n",
    "\n",
    "dataset = OctupleDataset(dataset_path, H.NOTES)\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=H.batch_size, shuffle=True)\n",
    "batch = next(iter(loader))\n",
    "print(f\"Batch shape: {batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Model and Sampler\n",
    "Initialize the Transformer model and wrap it in the AbsorbingDiffusion sampler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = Transformer(H).to(device)\n",
    "sampler = AbsorbingDiffusion(H, model, H.codebook_size).to(device)\n",
    "print(f\"Model initialized. Parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop Demonstration\n",
    "We will run a short training loop to demonstrate the optimization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(sampler.parameters(), lr=H.lr)\n",
    "sampler.train()\n",
    "\n",
    "print(\"Starting training loop demo (5 steps)...\")\n",
    "for step in range(5):\n",
    "    # Get batch\n",
    "    try:\n",
    "        x = next(iter(loader))\n",
    "    except StopIteration:\n",
    "        loader = torch.utils.data.DataLoader(dataset, batch_size=H.batch_size, shuffle=True)\n",
    "        x = next(iter(loader))\n",
    "        \n",
    "    x = x.to(device).long()\n",
    "    \n",
    "    # Forward pass calculates loss internally in AbsorbingDiffusion.train_iter\n",
    "    stats = sampler.train_iter(x)\n",
    "    loss = stats['loss']\n",
    "    \n",
    "    # Backward pass\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    \n",
    "    print(f\"Step {step+1}: Loss = {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training loop demo complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sampling Demonstration\n",
    "Generate samples using the trained model (note: model won't produce music after only 5 steps, but this demonstrates the mechanism)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.eval()\n",
    "print(\"Attempting to sample... \")\n",
    "with torch.no_grad():\n",
    "    # sample_steps=10 for speed demonstration\n",
    "    samples = sampler.sample(sample_steps=10, b=H.batch_size)\n",
    "    \n",
    "print(f\"Samples shape: {samples.shape}\")\n",
    "print(f\"Sample 0 (first 10 steps): \\n{samples[0][:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
